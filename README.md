# ğŸ‘©â€ğŸ”¬ğŸ§‘â€ğŸ’»ğŸ’†â€â™‚ï¸ LeWiDi Repository Data. Shared Task â€” Editions 1â€“3

This repository hosts material for all **three editions** of the LeWiDi shared task.

### Aim (in brief)
- **Embrace interpretative variation:** model and analyze disagreement rather than collapsing it away.  
- **Unified benchmarking:** offer a shared, comparable framework to train and evaluate systems on disagreement-aware data.  
- **From hard to soft labels:** encourage use of distributions/soft labels and perspectivist evaluation instead of single â€œgoldâ€ labels.  

## Editions & Datasets
### 2025 â€” 3rd Edition @ NLPerspectives (EMNLP 2025)
**Scope:** NLP; soft-label + perspectivist evaluation.  
**Datasets:**  
- **Conversational Sarcasm Corpus (CSC)** â€” sarcasm ratings (Likert 1â€“6)  
- **MultiPico (MP)** â€” multilingual irony detection in context  
- **Paraphrase Detection (Par)** â€” question-pair paraphrase judgments (Likert)  
- **VariErrNLI** â€” NLI with variation vs. error distinctions  

### 2023 â€” SemEval-2023 Task 11 (2nd Edition)
**Scope:** NLP, subjective tasks.  
**Datasets:**  
- **MD-Agreement** â€” offensiveness in English tweets  
- **ConvAbuse** â€” abusiveness in humanâ€“bot dialogues  
- **HS-Brexit** â€” hate speech/offensiveness around Brexit  
- **ArMIS** â€” Arabic misogyny/sexism  

### 2021 â€” SemEval-2021 Task 12 (1st Edition)
**Scope:** NLP + Computer Vision.  
**Datasets:**  
- **Twitter POS** (Gimpel et al.) â€” crowd-labeled POS tagging  
- **Phrase Detectives (PDIS)** â€” information status (Discourse New/Old)  
- **Humour** â€” pairwise funniness preference learning  
- **LabelMe** â€” 8-way image classification with crowd labels  
- **CIFAR-10H** â€” CIFAR-10 with human label distributions  
See the task paper for details.

## Repository Structure & Data Format
- Each top-level folder corresponds to an edition (**2021**, **2023**, **2025**) and contains that editionâ€™s **datasets and materials**.  
- **Data format note:** the datasets from the **second (2023)** and **third (2025)** editions are provided in the **same harmonized JSON format** (schema aligned across tasks).
